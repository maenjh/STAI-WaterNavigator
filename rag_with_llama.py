#!/usr/bin/env python3
"""
Llama-3, FAISS, Tavily APIë¥¼ ì‚¬ìš©í•œ RAG ì‹œìŠ¤í…œ
"""

import os
import torch
import warnings
import sys
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline
from langchain_community.llms import HuggingFacePipeline
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.agents import AgentExecutor, create_react_agent, Tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field
from langchain import hub

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings("ignore")

def create_rag_system():
    """RAG ì‹œìŠ¤í…œì„ ìƒì„±í•˜ê³  ì‹¤í–‰í•©ë‹ˆë‹¤."""
    
    # 1. ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„¤ì •
    model_path = "/workspace/models/Meta-Llama-3-8B"
    embedding_model_name = "jhgan/ko-sroberta-multitask"
    
    print("ğŸ¤– RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤...")

    # 4-bit ì–‘ìí™” ì„¤ì •
    quantization_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_compute_dtype=torch.float16,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_use_double_quant=True,
    )

    print(f"ğŸ§  Llama-3 ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤... (ê²½ë¡œ: {model_path})")
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        quantization_config=quantization_config,
        device_map="auto",
        trust_remote_code=True
    )
    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
    
    # LangChain íŒŒì´í”„ë¼ì¸ ìƒì„±
    pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        torch_dtype=torch.float16,
        max_new_tokens=512,
        repetition_penalty=1.1,
    )
    llm = HuggingFacePipeline(pipeline=pipe)
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

    # 2. ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    print(f"ğŸ–¼ï¸  ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤... (ëª¨ë¸: {embedding_model_name})")
    embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)
    print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

    # 3. ë¡œì»¬ ë²¡í„° DB (FAISS) ìƒì„±
    print("ğŸ“š ë¡œì»¬ ë²¡í„° DBë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    # ì˜ˆì œ ë¬¸ì„œ
    docs = [
        "ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„°ê°€ ì¸ê°„ì²˜ëŸ¼ í•™ìŠµí•˜ê³ , ì¶”ë¡ í•˜ê³ , ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "RAG (Retrieval-Augmented Generation)ëŠ” ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì˜ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.",
        "FAISSëŠ” Facebook AI Researchì—ì„œ ê°œë°œí•œ íš¨ìœ¨ì ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ ë° ë°€ì§‘ ë²¡í„° í´ëŸ¬ìŠ¤í„°ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
        "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤. ì„œìš¸ì€ ê²½ì œ, ë¬¸í™”, êµí†µì˜ ì¤‘ì‹¬ì§€ì…ë‹ˆë‹¤."
    ]
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    split_docs = text_splitter.create_documents(docs)
    
    vectorstore = FAISS.from_documents(split_docs, embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={'k': 2})
    print("âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ!")
    
    # 4. ë„êµ¬(Tools) ì •ì˜
    print("ğŸ› ï¸  ë„êµ¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤...")
    # 4-1. ë¡œì»¬ DB ê²€ìƒ‰ ë„êµ¬
    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    retrieval_chain = retriever | format_docs
    
    class LocalSearchInput(BaseModel):
        query: str = Field(description="ë¡œì»¬ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰í•  ì¿¼ë¦¬")

    class LocalSearchTool(BaseTool):
        name: str = "local_search"
        description: str = "AI, RAG, FAISS, í•œêµ­ ìˆ˜ë„ ë“± ë‚´ë¶€ ì •ë³´ì— ëŒ€í•´ ì§ˆë¬¸í•  ë•Œ ì‚¬ìš©í•˜ì„¸ìš”."
        args_schema: type[BaseModel] = LocalSearchInput

        def _run(self, query: str) -> str:
            """Use the tool."""
            docs = retrieval_chain.invoke(query)
            return docs if docs else "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    # 4-2. ì›¹ ê²€ìƒ‰ ë„êµ¬ (Tavily)
    tavily_search = TavilySearchResults(max_results=3)
    print("âœ… ë„êµ¬ ì •ì˜ ì™„ë£Œ!")
    
    tools = [
        LocalSearchTool(),
        Tool(
            name="tavily_search",
            description="ì‹¤ì‹œê°„ ì •ë³´, ìµœì‹  ë‰´ìŠ¤, íŠ¹ì • ì¸ë¬¼/ì¥ì†Œ/ì‚¬ê±´ ë“± ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸ì— ì‚¬ìš©í•˜ì„¸ìš”.",
            func=tavily_search.invoke
        )
    ]
    
    # 5. ì—ì´ì „íŠ¸ ìƒì„±
    print("ğŸ§‘â€âœˆï¸ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
    # ReAct í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
    prompt = hub.pull("hwchase17/react")
    
    agent = create_react_agent(llm, tools, prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
    print("âœ… ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ!")
    return agent_executor

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if "TAVILY_API_KEY" not in os.environ:
        print("âŒ TAVILY_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return

    agent_executor = create_rag_system()

    # ëª…ë ¹ì¤„ ì¸ìê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì¸ìë¥¼ ì§ˆë¬¸ìœ¼ë¡œ ì‚¬ìš©
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
        print("\n" + "="*50)
        print(f"ğŸ’¬ ì§ˆë¬¸: {query}")
        print("="*50)
        try:
            response = agent_executor.invoke({"input": query})
            print("\nğŸ’¡ ë‹µë³€:", response['output'])
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # ëŒ€í™”í˜• ëª¨ë“œ
    print("\n" + "="*50)
    print("ğŸ¤– RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ì¢…ë£Œ: 'exit')")
    print("="*50)
    
    while True:
        query = input("ğŸ’¬ ì§ˆë¬¸: ")
        if query.lower() == 'exit':
            break
        
        try:
            response = agent_executor.invoke({"input": query})
            print("\nğŸ’¡ ë‹µë³€:", response['output'])
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("\n" + "-"*50)

if __name__ == "__main__":
    main() 